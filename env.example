# Doc Flash Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================
# Choose your primary LLM provider: azure_openai, openai, gemini, or ollama
LLM_PROVIDER=azure_openai

# Global LLM settings
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=16000

# ============================================================================
# AZURE OPENAI CONFIGURATION
# ============================================================================
# Required if LLM_PROVIDER=azure_openai
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_MODEL_ID=gpt-4.1-mini
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1-mini
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here

# ============================================================================
# OPENAI CONFIGURATION  
# ============================================================================
# Required if LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL_ID=gpt-4.1-mini
# Optional: Custom base URL for OpenAI-compatible APIs
# OPENAI_BASE_URL=https://api.openai.com/v1

# ============================================================================
# GOOGLE GEMINI CONFIGURATION
# ============================================================================
# Required if LLM_PROVIDER=gemini
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_PROJECT_ID=your_google_project_id
GEMINI_MODEL_ID=gemini-1.5-flash

# ============================================================================
# OLLAMA CONFIGURATION (Local Models)
# ============================================================================
# Required if LLM_PROVIDER=ollama
OLLAMA_MODEL_ID=gemma2:2b
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# OCR PROVIDER CONFIGURATION (Optional - defaults to main LLM provider)
# ============================================================================
# Choose OCR provider: azure_openai, openai, gemini, ollama, or vllm
# If not set, will use the same provider as LLM_PROVIDER
OCR_PROVIDER=azure_openai
OCR_TEMPERATURE=0.0
OCR_MAX_TOKENS=16000

# Azure OpenAI OCR settings (uses same endpoint as main config)
# Recommended models for OCR: gpt-4.1, gpt-4.1-mini, gpt-4o, gpt-4o-mini, gpt-4-turbo
OCR_AZURE_OPENAI_MODEL_ID=gpt-4.1-mini
OCR_AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1-mini

# OpenAI OCR settings (uses same API key as main config)
# Recommended models for OCR: gpt-4.1, gpt-4.1-mini, gpt-4o, gpt-4o-mini, gpt-4-turbo
# OCR_OPENAI_MODEL_ID=gpt-4.1-mini

# Gemini OCR settings (uses same API key as main config)
# Recommended models for OCR: gemini-1.5-pro, gemini-1.5-flash
# OCR_GEMINI_MODEL_ID=gemini-1.5-flash

# Ollama OCR settings (uses same base URL as main config)
# Recommended vision models for OCR: llava:7b, llava:13b, bakllava, moondream2
# Note: OCR requires vision-capable models, not text-only models
# OCR_OLLAMA_MODEL_ID=llava:7b

# vLLM service configuration (nanonets-ocr or custom models)
# Use OCR_PROVIDER=vllm to explicitly use vLLM service
VLLM_SERVICE_URL=https://your-vllm-url

# File upload settings
MAX_CONTENT_LENGTH=16777216  # 16MB in bytes