# Doc Flash Configuration - vLLM/nanonets-ocr Setup
# This is an example based on your current setup

# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================
# Using Azure OpenAI for main LLM processing
LLM_PROVIDER=azure_openai

# Global LLM settings
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=16000

# ============================================================================
# AZURE OPENAI CONFIGURATION (Main LLM)
# ============================================================================
AZURE_OPENAI_ENDPOINT=https://your-azure-openai-endpoint/
AZURE_OPENAI_MODEL_ID=gpt-4.1-mini
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1-mini
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here

# ============================================================================
# OCR PROVIDER CONFIGURATION (vLLM/nanonets-ocr)
# ============================================================================
# Using vLLM service for OCR (your current setup)
# Set use_configured_provider=False to force vLLM usage
OCR_PROVIDER=vllm
OCR_TEMPERATURE=0.0
OCR_MAX_TOKENS=16000

# vLLM service configuration (your nanonets-ocr setup)
VLLM_SERVICE_URL=https://your-vllm-endpoint


# File upload settings
MAX_CONTENT_LENGTH=16777216  # 16MB in bytes

# ============================================================================
# OPTIONAL: Alternative Configurations
# ============================================================================
# If you want to try Azure OpenAI for OCR as well, uncomment below:
# OCR_PROVIDER=azure_openai
# OCR_AZURE_OPENAI_MODEL_ID=gpt-4o-mini
# OCR_AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini

# If you want to try OpenAI for main LLM, uncomment below:
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL_ID=gpt-4.1-mini